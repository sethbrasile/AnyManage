---
phase: 06-voice-training-system
plan: 03
type: execute
wave: 3
depends_on: ["06-02"]
files_modified:
  - docs/protocols/voice-application.md
  - docs/protocols/correction-learning.md
  - docs/protocols/specialist-coordination.md
autonomous: true

must_haves:
  truths:
    - "User can select different tones for different outputs via modifiers"
    - "Voice auto-applies to appropriate content types at agent discretion"
    - "User can learn from corrections via in-session or async paths"
    - "Specialists integrate with voice system for client-facing deliverables"
    - "Correction reminders appear at appropriate frequency"
  artifacts:
    - path: "docs/protocols/voice-application.md"
      provides: "Voice application protocol with modifiers"
      min_lines: 150
    - path: "docs/protocols/correction-learning.md"
      provides: "Correction learning protocol"
      min_lines: 100
    - path: "docs/protocols/specialist-coordination.md"
      provides: "Updated specialist protocol with voice integration"
      contains: "voice"
  key_links:
    - from: "docs/protocols/voice-application.md"
      to: "~/.agent-pm/voice/voice_profile.md"
      via: "profile loading"
      pattern: "\\.agent-pm/voice"
    - from: "docs/protocols/specialist-coordination.md"
      to: "docs/protocols/voice-application.md"
      via: "voice integration for deliverables"
      pattern: "voice-application"
---

<objective>
Create voice application protocol, correction learning protocol, and integrate voice system with specialists.

Purpose: Enable the system to actually USE trained voice profiles. This completes the voice system by defining when and how voice is applied, how the system learns from corrections, and how specialists leverage voice for client-facing deliverables.

Output: Voice application protocol, correction learning protocol, updated specialist coordination protocol with voice integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-voice-training-system/06-CONTEXT.md
@.planning/phases/06-voice-training-system/06-RESEARCH.md
@.planning/my_voice_example/llm_implementation_guide.md
@.planning/phases/06-voice-training-system/06-01-SUMMARY.md
@.planning/phases/06-voice-training-system/06-02-SUMMARY.md
@docs/protocols/specialist-coordination.md
@INSTRUCTIONS.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create voice application protocol</name>
  <files>docs/protocols/voice-application.md</files>
  <action>
Create the voice application protocol at `docs/protocols/voice-application.md`.

This protocol defines when and how to apply the user's voice to generated content.

```markdown
# Voice Application Protocol

**Purpose:** Apply trained voice profiles to generated content at appropriate times.

**Prerequisites:** Voice profile exists at `~/.agent-pm/voice/voice_profile.md` or `ops/voice/voice_profile.md`

---

## Profile Loading

### Loading Order

1. **Check primary:** `~/.agent-pm/voice/voice_profile.md`
   - If found: Load and use (personal voice, portable)

2. **Check fallback:** `ops/voice/voice_profile.md`
   - If found: Load and use (project-specific)

3. **If neither found:**
   - Proceed without voice application
   - If user explicitly requests voice: "No voice profile found. Run 'Train my voice' to create one."

### Profile Validation

When loading profile, verify:
- File is valid markdown
- Contains "CORE VOICE DNA" section
- Contains at least one content-type section (EMAIL, TECHNICAL, etc.)

If validation fails: Warn user, offer to re-train.

### Profile Age Check

Read "Last trained:" date from profile footer.

If profile is older than 6 months:
- Note: "Your voice profile was trained [X] months ago. If your writing style has evolved, consider refreshing with 'Train my voice' again."
- Only show this note once per session

---

## Auto-Activation Rules

Voice applies automatically based on content type (agent discretion):

### Likely Auto-Apply

Content types where voice typically enhances output:

| Content Type | Auto-Apply | Rationale |
|--------------|------------|-----------|
| Client emails | Yes | External communication benefits from personal voice |
| Proposals | Yes | Professional but personal tone is valued |
| External documentation | Yes | User-facing content should sound authentic |
| Meeting follow-ups | Yes | Professional correspondence |
| Status updates to clients | Yes | Relationship maintenance |

### Likely Manual-Only

Content types where neutral/formal tone is often preferred:

| Content Type | Auto-Apply | Rationale |
|--------------|------------|-----------|
| Internal notes | No | May prefer neutral tone |
| Technical documentation | No | Often prefers objectivity |
| Code comments | No | Standard conventions apply |
| Internal strategy docs | No | May share with team members |
| Legal/compliance content | No | Formal requirements |

### User Override

- **Force voice on:** "Write this in my voice" or "Apply my voice"
- **Suppress voice:** "Write this neutrally" or "Don't use my voice"

User override always takes precedence over auto-activation rules.

---

## Tone Calibration Modifiers

Single voice profile adapts via modifiers for different contexts:

### Available Modifiers

**Professional Client**
- Slightly more structured
- Clear timelines and expectations
- Transparent about process
- Maintains warmth but adds precision

**Business Partner / Team**
- More direct, assume shared knowledge
- Skip unnecessary context
- Shorthand acceptable
- Higher casualness threshold

**Formal**
- Structure increases
- Casualness decreases
- Keep core voice patterns (parentheticals, etc.) but dial back
- No humor unless very subtle

**Casual**
- Full informal mode
- All voice patterns apply
- Humor fully enabled
- Fragments and run-ons acceptable

**Family Member Client** (special case)
- Professional about project details
- Slightly warmer
- No emojis
- Professional boundaries maintained

### Applying Modifiers

User can request modifier via natural language:
- "Write a formal email to [client]" -> Apply formal modifier
- "Quick message to the team about [topic]" -> Apply team modifier
- "Email to [family member] about their project" -> Apply family client modifier

If no modifier specified:
- Default to "professional client" for external recipients
- Default to "business partner" for internal team
- Infer from context when possible

### Modifier Implementation

When applying modifier, adjust:
1. Structure level (more/less organized)
2. Hedging frequency (more/less tentative)
3. Humor threshold (when to include "lol" etc.)
4. Paragraph length
5. Opening/closing formality

Do NOT change:
- Core voice DNA patterns
- Anti-patterns (things to never say)
- Fundamental sentence structure preferences

---

## Application Process

When generating content with voice:

### Step 1: Load Profile

```
profile = load_voice_profile()
if not profile:
  continue_without_voice()
  return
```

### Step 2: Determine if Auto-Apply

```
content_type = detect_content_type(request)
should_apply = check_auto_activation(content_type)
user_override = check_user_override(request)

if user_override == "force_on":
  apply_voice = true
elif user_override == "force_off":
  apply_voice = false
else:
  apply_voice = should_apply
```

### Step 3: Select Modifier

```
modifier = detect_modifier(request, recipient)
# Returns: professional_client | business_partner | formal | casual | family_client
```

### Step 4: Generate with Voice

Apply voice profile patterns:
1. Use Core Voice DNA for fundamental patterns
2. Apply content-type specific patterns
3. Apply modifier adjustments
4. Run anti-pattern check (ensure nothing from "Things I Never Say")
5. Apply quality checklist mentally before output

### Step 5: Offer Correction Learning

After generating voice-applied content (see correction-learning.md for frequency rules):

```
Did you make edits before sending? Paste your edits so I can learn!
```

---

## Quality Verification

Before outputting voice-applied content, verify:

- [ ] No phrases from "Things [User] Never Say" list
- [ ] Appropriate parenthetical asides (if profile indicates)
- [ ] Contractions used naturally (if profile indicates)
- [ ] Opening matches profile patterns
- [ ] Closing is specific and actionable
- [ ] Paragraph length matches profile
- [ ] Modifier appropriately applied

If quality check fails on any item, revise before output.

---

## Error Handling

### Profile Not Found

- Inform user: "No voice profile found. Generate content without voice?"
- If user wanted voice: Offer "Train my voice" to create profile

### Profile Corrupted

- Warn user about invalid profile
- Offer to view profile for manual fix
- Offer to re-train

### Modifier Conflict

If user requests conflicting modifiers:
- "You asked for both formal and casual tone. Which would you prefer?"

---

## Integration

### Related Protocols

- `voice-training.md` - Creating voice profiles
- `correction-learning.md` - Learning from user corrections
- `specialist-coordination.md` - Specialists using voice

### INSTRUCTIONS.md Reference

Voice Training section in INSTRUCTIONS.md provides overview.

---

## Examples

### Example 1: Auto-Applied Client Email

```
User: Write an email to Diana about the brochure timeline

[Agent loads profile, detects "email to client", auto-applies voice with professional_client modifier]

Agent:
Diana,

Quick update on the brochure timeline. We're waiting on specs from your printer before the designer can start (different printers have different requirements for bleeds and such).

Once we have those, I'm estimating 2-3 weeks to finished design. Could you check with them and let me know?

Also - could you add samuel@pricklypearmarketingco.com to the Google Drive? He'll be doing the design work.

Let me know if you need anything else from my end.

---

Did you make edits before sending? Paste your edits so I can learn!
```

### Example 2: Voice Suppressed for Technical Doc

```
User: Write documentation for our API endpoints. Don't use my voice - keep it technical.

[Agent suppresses voice per user override]

Agent:
# API Endpoints

## Authentication

POST /api/auth/login
- Request: { email: string, password: string }
- Response: { token: string, expires: number }
...
```

### Example 3: Modifier Adjustment

```
User: Write a more formal email to the Johnson Law Firm about our proposal

[Agent applies formal modifier]

Agent:
Dear Ms. Johnson,

Thank you for the opportunity to submit our proposal for the website redesign project.

Based on our initial discussion, I've outlined the scope, timeline, and investment below. (I've also included our standard terms, but we can certainly discuss adjustments if needed.)

[Content with voice but more structured, fewer casual markers]

Please let me know if you have any questions about the proposal.

Best regards,
[Signature]
```

---

*Protocol version: 1.0*
*Created: [DATE]*
```

This protocol covers:
- VOIC-05 (selectable voice per output type via modifiers)
- VOIC-06 (voice-aware writing)
  </action>
  <verify>File exists at docs/protocols/voice-application.md with profile loading, auto-activation rules, tone calibration modifiers, and application process</verify>
  <done>Voice application protocol exists with complete workflow for applying voice to generated content</done>
</task>

<task type="auto">
  <name>Task 2: Create correction learning protocol</name>
  <files>docs/protocols/correction-learning.md</files>
  <action>
Create the correction learning protocol at `docs/protocols/correction-learning.md`.

This protocol defines how the system learns from user corrections to improve voice accuracy.

```markdown
# Correction Learning Protocol

**Purpose:** Learn from user corrections to continuously improve voice profile accuracy.

**Principle:** Every correction is a learning opportunity. The system should get better over time.

---

## Two Correction Paths

### Path 1: In-Session (Conversational)

User provides corrections during the conversation.

**Trigger phrases:**
- "Here's what I changed: [paste]"
- "I edited it to: [paste]"
- "Actually I sent: [paste]"
- "My version: [paste]"

**Process:**

1. **Capture original** - Store what agent generated
2. **Receive correction** - User pastes edited version
3. **Analyze diff** - Identify what changed:
   - Removed phrases/patterns
   - Added phrases/patterns
   - Structural changes
   - Tone adjustments
4. **Extract patterns:**
   - "User removed [X]" -> Consider adding to anti-patterns
   - "User added [Y]" -> Consider adding to patterns
   - "User restructured [Z]" -> Update structural preferences
5. **Update profile** - Modify voice profile with learned patterns
6. **Confirm** - Tell user what was learned:
   "Updated voice profile to reflect: [specific changes]"

**Example:**

```
Agent: [Generated email with "I hope this helps clarify things"]

User: Here's what I changed:
[Paste without that phrase, different closing]

Agent: I see you removed "I hope this helps clarify things" and changed the
closing to be more specific. I've updated your voice profile to:
- Add "I hope this helps clarify things" to anti-patterns
- Note preference for specific action-item closings

Your profile will reflect these changes going forward.
```

### Path 2: Async (File-Based)

User adds corrections to a log file for later processing.

**File location:** `ops/voice/CORRECTIONS.md`

**Format:**

```markdown
# Voice Corrections Log

## Correction [DATE]

**AI Generated:**
[Paste original AI output]

**My Edit:**
[Paste your corrected version]

**What Changed:**
[Optional: Note specific changes]

---

## Correction [DATE]

[Next entry...]
```

**Processing:**

Agent processes CORRECTIONS.md when:
- User says "Learn from my corrections" or "/process-corrections"
- During voice-related operations (check if file has new entries)
- Periodically if file modified recently

**Process:**

1. Read CORRECTIONS.md
2. For each unprocessed entry:
   - Analyze AI output vs user edit
   - Extract patterns
   - Update voice profile
   - Mark entry as processed (add checkmark or move to "Processed" section)
3. Summarize what was learned
4. Optionally clear processed entries (ask user preference)

---

## Reminder Frequency

Show correction learning reminder after voice-applied content:

### Frequency Rules

| Situation | Show Reminder |
|-----------|---------------|
| First 3 times voice is applied | Yes (learning phase) |
| Every 5th application after that | Yes (reinforcement) |
| User explicitly requests voice | Yes |
| User has never provided a correction | Yes (encourage first correction) |
| User recently provided correction | No (they know the feature) |

### Tracking

Track reminder state in `ops/voice/.reminder_state` (simple JSON):

```json
{
  "voice_applications": 12,
  "last_reminder": 10,
  "corrections_received": 3,
  "last_correction": "2026-01-25"
}
```

### Reminder Text

```
Did you make edits before sending? Paste your edits so I can learn!
```

Keep it brief. Don't explain the feature every time.

For first-time users, add context:
```
Tip: If you edit this before sending, paste your edits and I'll learn
from the changes. This helps me sound more like you over time.
```

---

## Pattern Extraction

When analyzing corrections:

### What to Look For

**Removed content** (potential anti-patterns):
- Phrases user consistently removes
- Structural patterns user eliminates
- Formality markers user strips

**Added content** (potential patterns):
- Phrases user consistently adds
- Structural patterns user introduces
- Casual markers user inserts

**Changed content** (preference signals):
- Formal -> casual (or vice versa)
- Long -> short (or vice versa)
- Structured -> flowing (or vice versa)

### Pattern Confidence

Don't update profile on single correction. Look for:
- Same pattern in 2-3 corrections -> Consider updating profile
- Same pattern in 4+ corrections -> Definitely update profile

Track pattern frequency before committing to profile changes.

### Pattern Conflict

If new correction conflicts with existing profile:
- Ask user: "Your recent edit conflicts with your profile. You said you never use [X], but you just added it. Should I update your profile?"
- User confirms: Update profile
- User explains: "That was a special case" -> Don't update

---

## Profile Update Process

When updating profile based on corrections:

### Adding Anti-Patterns

1. Identify phrase/pattern user removed
2. Check if already in anti-patterns list
3. If not, add to "THINGS [USER] NEVER SAYS" section
4. Add specific example if helpful

### Adding Patterns

1. Identify phrase/pattern user added
2. Determine appropriate section (Core DNA, Email Patterns, etc.)
3. Add to relevant DO list
4. Add specific example if helpful

### Updating Examples

1. Replace generic examples with user's actual corrections
2. "AI writes: [X], User writes: [Y]" format
3. Keep examples fresh and relevant

### Quality Checklist Updates

If pattern is easily verifiable, add to quality checklist:
- "No [removed phrase]"
- "Include [added phrase] when appropriate"

---

## Error Handling

### Unclear Correction

If can't determine what changed:
- Ask user: "I'm having trouble seeing what you changed. Could you tell me the specific edit?"

### Conflicting Corrections

If user makes opposite corrections:
- Don't update profile
- Ask: "I've seen you both add and remove [pattern]. Is this context-dependent?"

### Profile Write Failure

If can't update profile file:
- Store pending updates in memory
- Retry on next opportunity
- Inform user if persistent failure

---

## Integration

### Related Protocols

- `voice-training.md` - Initial profile creation
- `voice-application.md` - Using voice profiles

### Commands

- "Learn from my corrections" -> Process CORRECTIONS.md
- "What have you learned from my edits?" -> Show recent profile updates

---

## Examples

### Example 1: In-Session Correction

```
Agent: [Generated email ending with "Please let me know if you have any questions."]

User: Here's what I actually sent:
[Same email but ending with "Let me know if anything needs adjustment."]

Agent: Got it! I see you changed the closing from "Please let me know if
you have any questions" to "Let me know if anything needs adjustment."

I've updated your voice profile to note:
- Avoid "Please let me know if you have any questions" (added to anti-patterns)
- Prefer specific, action-oriented closings

This matches your existing pattern of direct, specific closings.
```

### Example 2: Async Correction Processing

```
User: Learn from my corrections

Agent: [Reads ops/voice/CORRECTIONS.md, finds 3 new entries]

I processed 3 corrections from your log:

1. Learned: You prefer "quick update" over "I wanted to follow up"
2. Learned: You use em-dashes more than I was generating
3. Learned: You end questions with single "?" not "??"

Updated your voice profile with these patterns. The corrections log has
been marked as processed.
```

---

*Protocol version: 1.0*
*Created: [DATE]*
```

This protocol enables continuous improvement of voice profiles.
  </action>
  <verify>File exists at docs/protocols/correction-learning.md with two correction paths (in-session, async), reminder frequency rules, and pattern extraction process</verify>
  <done>Correction learning protocol exists with complete workflow for learning from user edits</done>
</task>

<task type="auto">
  <name>Task 3: Update specialist coordination protocol with voice integration</name>
  <files>docs/protocols/specialist-coordination.md</files>
  <action>
Update the existing `docs/protocols/specialist-coordination.md` to integrate voice system.

Read the current file and add a new section for voice integration. Do NOT rewrite the entire file - only add the voice integration section.

Add the following section after the "Deliverable Creation" section and before "Error Handling":

```markdown
---

## Voice Integration

Specialists can apply the user's voice to client-facing deliverables.

### When to Apply Voice

| Deliverable Type | Apply Voice | Rationale |
|------------------|-------------|-----------|
| Client-facing reports | Yes (if profile exists) | Maintains user's authentic tone |
| External proposals | Yes (if profile exists) | Professional but personal |
| Internal analysis | No | Neutrality preferred |
| Technical specifications | No | Objectivity required |
| Meeting summaries for clients | Yes (if profile exists) | Relationship maintenance |
| Internal strategy docs | No | May be shared with team |

### Voice Loading for Specialists

When specialist starts:

1. Check if voice profile exists:
   - Primary: `~/.agent-pm/voice/voice_profile.md`
   - Fallback: `ops/voice/voice_profile.md`

2. If profile exists and deliverable is client-facing:
   - Load profile into specialist context
   - Apply voice patterns to final deliverable

3. If profile doesn't exist:
   - Generate deliverable without voice
   - Note: "Voice profile not found - using neutral tone"

### Voice Application in Deliverables

When applying voice to specialist deliverables:

**Assessment Specialist:**
- Apply voice to executive summary
- Apply voice to recommendations section
- Keep data/findings sections neutral

**Strategy Specialist:**
- Apply voice to overview and rationale
- Apply voice to recommended next steps
- Keep technical details neutral

### Modifier Selection for Specialists

Default modifier for specialist deliverables: `professional_client`

Override based on context:
- Known casual relationship -> `business_partner`
- Formal industry (legal, finance) -> `formal`
- User explicitly requests tone -> Use specified modifier

### Post-Generation Reminder

After specialist generates voice-applied deliverable:

Include correction learning reminder (following frequency rules from correction-learning.md):

```
Did you make edits before sharing this deliverable? Paste your edits so I can learn!
```

### Integration Protocol Reference

See `docs/protocols/voice-application.md` for complete voice application details.
See `docs/protocols/correction-learning.md` for correction learning workflow.
```

Insert this section in the appropriate location within the existing file. Maintain the existing structure and content of specialist-coordination.md.
  </action>
  <verify>File docs/protocols/specialist-coordination.md contains new "Voice Integration" section with voice loading, application rules, and modifier selection for specialists</verify>
  <done>Specialist coordination protocol updated with voice integration for client-facing deliverables</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Voice application protocol exists:**
   - `docs/protocols/voice-application.md` exists
   - Contains profile loading order (home > project)
   - Contains auto-activation rules (what auto-applies)
   - Contains tone calibration modifiers (5 modifiers)
   - Contains application process
   - Contains quality verification checklist

2. **Correction learning protocol exists:**
   - `docs/protocols/correction-learning.md` exists
   - Contains two correction paths (in-session, async)
   - Contains reminder frequency rules
   - Contains pattern extraction process
   - Contains profile update process

3. **Specialist coordination updated:**
   - `docs/protocols/specialist-coordination.md` contains voice integration section
   - Documents when to apply voice to specialist deliverables
   - References voice-application.md and correction-learning.md
</verification>

<success_criteria>
1. Voice application protocol defines when voice auto-applies vs manual
2. Five tone calibration modifiers are documented (professional_client, business_partner, formal, casual, family_client)
3. Correction learning provides two paths (in-session and async file)
4. Reminder frequency follows rules (first 3, then every 5th)
5. Specialist coordination integrates voice for client-facing deliverables
6. All protocols reference each other appropriately
</success_criteria>

<output>
After completion, create `.planning/phases/06-voice-training-system/06-03-SUMMARY.md`
</output>
